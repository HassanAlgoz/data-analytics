{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "\n",
    "We will explore:\n",
    "\n",
    "1. Foundations\n",
    "2. Processes\n",
    "3. Tools\n",
    "\n",
    "of Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story: John Snow and the Broad Street Pump\n",
    "\n",
    "In the 1850s, London faced severe cholera outbreaks. The prevailing theory was that \"miasmas\" (bad smells from decaying matter) caused the disease. Dr. John Snow doubted this and observed that while cholera wiped out entire households, neighboring houses remained unaffected despite sharing the same air. Snow also noted that cholera victims suffered from vomiting and diarrhea, suggesting water contamination as the culprit.\n",
    "\n",
    "In August 1854, when cholera hit Soho, Snow mapped the location of cholera deaths and found that many victims lived near the Broad Street pump.\n",
    "\n",
    "- He also noted that deaths near the Rupert Street pump were from residents who preferred using the more convenient Broad Street pump.\n",
    "- No deaths occurred at the Lion Brewery, where workers drank only brewed beer and water from their own well.\n",
    "- Deaths in distant houses involved children who drank from the Broad Street pump on their way to school.\n",
    "\n",
    "Snow's observations led him to conclude that the Broad Street pump was the source of the cholera outbreak. He convinced local authorities to remove the pump handle, and surely enough, the outbreak subsided, preventing further deaths.\n",
    "\n",
    "![Death Counts Mapped in the neighborhood](../assets/snows-mapped-death-frequency.png)\n",
    "\n",
    "Source: [Data 8](https://inferentialthinking.com/chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinson's Law\n",
    "\n",
    "Individual observations are grouped together to form a sample, on which one might draw conclusions about the population.\n",
    "\n",
    "Example: **Parkinson's Law** states that \"Work expands to fill the time available for its completion.\"\n",
    "\n",
    "![](../assets/parkinsons-law.png)\n",
    "\n",
    "Image Source: consuunt.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistics** is a tool that applies to many fields, including business, finance, economics, biology, sociology, psychology, education, public health, and sports.\n",
    "\n",
    "- **Snow** applied statistics to track the root cause of the cholera outbreak in a way that's scientifically sound to the authorities by analyzing the data of the deaths.\n",
    "- **Parkinson's Law** is a funny example of how staistical plots can be used to express a joke or an real observation.\n",
    "\n",
    "There are two major fields of statistics:\n",
    "\n",
    "1. Descriptive statistics\n",
    "2. Inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "\n",
    "***Descriptive statistics*** summarizes qualities of a group (of people or things) numerically and visually.\n",
    "\n",
    "Numerical summaries are divided into these main categories:\n",
    "\n",
    "1. **Frequency** (proportion)\n",
    "1. **Measures of Central Tendency** (mean, median, mode)\n",
    "1. **Measures of Dispersion** (range, variance, standard deviation)\n",
    "1. **Measures of Shape** (skewness, kurtosis)\n",
    "\n",
    "Visual summaries uses graphical representations such as:\n",
    "- Histogram\n",
    "- Bar chart\n",
    "- Box plot\n",
    "\n",
    "![](../assets/data-viz-examples.png)\n",
    "\n",
    "Example: In Snow's case, the data is the location of the cholera deaths. The frequency is the number of deaths in each location. The measures of central tendency are the location of the most deaths. The measures of dispersion are the range of the locations of the deaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferential Statistics\n",
    "\n",
    "***Inferential Statistics*** make statements about a population based on samples:\n",
    "\n",
    "1. ***Estimation***: make informed guess about population parameters. Example:\n",
    "    - How many people in the population are obese?\n",
    "    - What is the median income of housesholds in region X?\n",
    "2. ***Comparison***: finding out if differences are actually caused by some variable(s), or just due to random chance. Example:\n",
    "    - What is the impact of a new drug on the recovery time of patients?\n",
    "    - What is the impact of a new teaching method on student performance?\n",
    "3. ***Relationships***: quantifying the magnitude of the relationship between to variables, where we can do a “what if” analysis. Example:\n",
    "    - How much more can a house sell for an additional bedroom?\n",
    "    - What is the impact of lot size on housing price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Inferential Statistics](../assets/inferential-statistics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Data Science?\n",
    "\n",
    "A **Data Point** is an **Observation**. When collected, data describe the phenomenon we are analyzing. But, first, we store them on computers.\n",
    "\n",
    "- Data can be numbers, words, images, sounds, etc.\n",
    "- Data also falls into types.\n",
    "\n",
    "There is alot to say about data .. hence, we have Data Science.\n",
    "\n",
    "**Data Science** is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It combines principles and techniques from statistics, computer science, and domain-specific knowledge to analyze, interpret, and leverage data for decision-making and predictive analytics.\n",
    "\n",
    "- **Statistics** is essential since it studies how to make robust conclusions based on incomplete information.\n",
    "- **Computer science** is essential because data are stored on computers and analyzed by algorithms.\n",
    "- **Domain knowledge** is essential for asking the right questions and for understanding the answers produced by computational tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/Data-Science-Venn-Diagram.png)\n",
    "\n",
    "Image Source: https://www.researchgate.net/figure/Data-Science-Venn-Diagram_fig1_365946272"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did Snow do it?\n",
    "\n",
    "- **Domain Knowledge**: Snow is a doctor\n",
    "- **Match & Statistics**: Snow used data, plotted it, and drew conclusions\n",
    "- **Computer Science**: Snow did not have computers, but the data was stored on paper, and he did not need to do much computations.\n",
    "\n",
    "Computers help us deal with big amounts of data. They help **the government, the police, the military, the business, etc**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes of Data Science\n",
    "\n",
    "Data Science is three processes:\n",
    "\n",
    "1) **Exploration**: Identifying patterns in information. It involves:\n",
    "    - *Descriptive Statistics*\n",
    "    - *Visualization*\n",
    "\n",
    "2) **Inference**: draw conclusions about a population based on samples of data taken from that population. It involves:\n",
    "    - *Estimation*\n",
    "    - *Comparison*\n",
    "    - *Relationship*\n",
    "\n",
    "3) **Prediction**: fill in the missing values based on other values. It involves:\n",
    "    - *Machine Learning*\n",
    "    - ~~*Optimization*~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "We mentioned exploration and inference, but what is *Prediction*?\n",
    "\n",
    "If the time it takes to commute to the bootcamp location:\n",
    "\n",
    "- Last week on Sunday it took me 50 minutes\n",
    "- On Monday it took 48 minutes\n",
    "- On Tuesday: 52 minutes\n",
    "- On Wednesday: 49 minutes\n",
    "- On Thursday: ... (how much time will it take?)\n",
    "\n",
    "**Time-wise**: prediction can be about the future, the past, or missing in-between. **In general**: missing values can be inferred from other values, after the pattern is learned from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python tools for data science are built on top of the following fundamental packages/libraries:\n",
    "\n",
    "- **NumPy**: The fundamental **package** for scientific computing with Python.\n",
    "- **SciPy**: Fundamental **algorithms** for scientific computing in Python.\n",
    "- **Matplotlib** is a comprehensive library for creating static, animated, and interactive **visualizations** in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Numpy Languages](../assets/numpy-languages.png)\n",
    "\n",
    "Such Python libraries use **C** underneath to achieve high performance, yet provides it in a simple Pythonic Interface / API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Wrangling and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pandas\n",
    "\n",
    "**Pandas** provides fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It is built on top of **NumPy**, which is built on top of **C**. So, it is really fast.\n",
    "\n",
    "#### Get started\n",
    "\n",
    "To get started with Pandas, follow the official [Getting started tutorials](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html).\n",
    "\n",
    "#### Exercises\n",
    "\n",
    "To get some exercise, follow the Kaggle Courses:\n",
    "\n",
    "- Learn Pandas: https://www.kaggle.com/learn/pandas\n",
    "- Data Cleaning: https://www.kaggle.com/learn/data-cleaning\n",
    "- Feature Engineering: https://www.kaggle.com/learn/feature-engineering\n",
    "\n",
    "#### Mindmap (Cheat Sheet)\n",
    "\n",
    "You may also look at the following Pandas Mind Map:\n",
    "\n",
    "- https://xmind.ai/share/ugVH30g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Seaborn\n",
    "\n",
    "- Create publication quality plots.\n",
    "- Make interactive figures that can zoom, pan, update.\n",
    "- Customize visual style and layout.\n",
    "- Export to many file formats.\n",
    "- Embed in JupyterLab and Graphical User Interfaces.\n",
    "- Use a rich array of third-party packages built on Matplotlib.\n",
    "\n",
    "**Seaborn** is a library for making statistical graphics in Python. It builds on top of **matplotlib** and integrates closely with **pandas** data structures.\n",
    "\n",
    "- Seaborn Intro: https://seaborn.pydata.org/tutorial/introduction.html\n",
    "- Matplotlib (low-level) user guide: https://matplotlib.org/stable/users/index.html#users-guide-index\n",
    "\n",
    "Kaggle Courses:\n",
    "\n",
    "- Data Visualization: https://www.kaggle.com/learn/data-visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Statistical Packages\n",
    "\n",
    "**Statsmodels**: statistical models, hypothesis tests, and data exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Machine Learning (Pattern Recognition)\n",
    "\n",
    "**Scikit-learn**:\n",
    "\n",
    "- Simple and efficient tools for predictive data analysis\n",
    "- Accessible to everybody, and reusable in various contexts\n",
    "- Built on NumPy, SciPy, and matplotlib\n",
    "- Open source, commercially usable - BSD license\n",
    "\n",
    "**PyCaret**: an alternate low-code library that can be used to replace hundreds of lines of code with few words only. This makes experiments exponentially fast and efficient. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, LightGBM, CatBoost, Optuna, Hyperopt, Ray, and many more."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
