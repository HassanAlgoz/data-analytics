{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "\n",
    "Foundations & Tools of Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story: John Snow and the Broad Street Pump\n",
    "\n",
    "In the 1850s, London faced severe cholera outbreaks. The prevailing theory was that \"miasmas\" (bad smells from decaying matter) caused the disease. Dr. John Snow doubted this and observed that while cholera wiped out entire households, neighboring houses remained unaffected despite sharing the same air. Snow also noted that cholera victims suffered from vomiting and diarrhea, suggesting water contamination as the culprit.\n",
    "\n",
    "In August 1854, when cholera hit Soho, Snow mapped the location of cholera deaths and found that many victims lived near the Broad Street pump.\n",
    "\n",
    "- He also noted that deaths near the Rupert Street pump were from residents who preferred using the more convenient Broad Street pump.\n",
    "- No deaths occurred at the Lion Brewery, where workers drank only brewed beer and water from their own well.\n",
    "- Deaths in distant houses involved children who drank from the Broad Street pump on their way to school.\n",
    "\n",
    "Snow's observations led him to conclude that the Broad Street pump was the source of the cholera outbreak. He convinced local authorities to remove the pump handle, and surely enough, the outbreak subsided, preventing further deaths.\n",
    "\n",
    "![Death Counts Mapped in the neighborhood](../assets/snows-mapped-death-frequency.png)\n",
    "\n",
    "Source: [Data 8](https://inferentialthinking.com/chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinson's Law\n",
    "\n",
    "Individual observations are grouped together to form a sample, on which one might draw conclusions about the population.\n",
    "\n",
    "Example: **Parkinson's Law** states that \"Work expands to fill the time available for its completion.\"\n",
    "\n",
    "![](../assets/parkinsons-law.png)\n",
    "\n",
    "Image Source: consuunt.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistics** is a tool that applies to many fields, including business, finance, economics, biology, sociology, psychology, education, public health, and sports.\n",
    "\n",
    "- **Snow** applied statistics to track the root cause of the cholera outbreak in a way that's scientifically sound to the authorities by analyzing the data of the deaths.\n",
    "- **Parkinson's Law** is a funny example of how staistical plots can be used to express a joke or an real observation.\n",
    "\n",
    "There are two major fields of statistics:\n",
    "\n",
    "1. Descriptive statistics\n",
    "2. Inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "\n",
    "***Descriptive statistics*** summarizes qualities of a group (of people or things) numerically and visually.\n",
    "\n",
    "Visual summaries uses graphical representations such as:\n",
    "\n",
    "- Histogram\n",
    "- Bar chart\n",
    "- Box plot\n",
    "\n",
    "![](../assets/data-viz-examples.png)\n",
    "\n",
    "Example: In Snow's case, the data is the location of the cholera deaths. The frequency is the number of deaths in each location. The measures of central tendency are the location of the most deaths. The measures of dispersion are the range of the locations of the deaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferential Statistics\n",
    "\n",
    "***Inferential Statistics*** goes beyond description and into:\n",
    "\n",
    "1. making informed guess about a group of people / items\n",
    "2. verify claims through data; e.g., coffee and sleep\n",
    "\n",
    "<img src=\"https://datatab.net/assets/tutorial/Descriptive_statistics_and_inferential_statistics.png\">\n",
    "\n",
    "Source: Datatab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Data Science?\n",
    "\n",
    "A **Data Point** is an **Observation**. When collected, data describe the phenomenon we are analyzing. But, first, we store them on computers.\n",
    "\n",
    "- Data can be numbers, words, images, sounds, etc.\n",
    "- Data also falls into types.\n",
    "\n",
    "There is alot to say about data .. hence, we have Data Science.\n",
    "\n",
    "> **Data Science** is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It combines principles and techniques from statistics, computer science, and domain-specific knowledge to analyze, interpret, and leverage data for decision-making and predictive analytics.\n",
    "\n",
    "- **Domain Knowledge** is essential for asking the right questions and for understanding the answers produced by computational tools.\n",
    "- **Math & Statistics** studies how to make robust conclusions based on incomplete information.\n",
    "- **Computer Science** is needed since data are stored on computers and processed by algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/Data-Science-Venn-Diagram.png)\n",
    "\n",
    "Image Source: https://www.researchgate.net/figure/Data-Science-Venn-Diagram_fig1_365946272"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did Snow do it?\n",
    "\n",
    "- **Domain Knowledge**: Snow is a doctor\n",
    "- **Math & Statistics**: Snow used data, plotted it, and drew conclusions\n",
    "- **Computer Science**: Snow did not have computers, but the data was stored on paper, and he did not need to do much computations.\n",
    "\n",
    "Computers help us deal with big amounts of data. Be it in terms of speed or storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "> **Data analysis** is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making.\n",
    "\n",
    "Two approaches to data analysis:\n",
    "\n",
    "1. **Top-Down** (Confirmatory - CDA)\n",
    "    - Start with a question and use data to answer it.\n",
    "2. **Bottom-Up** (Exploratory - EDA)\n",
    "    - Start with the data and try to find something interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 4 Types of Data Analytics\n",
    "\n",
    "1. **Descriptive Analytics** (What happened?): This is the foundation of business reporting. It uses historical data to summarize performance.\n",
    "   - Example: A retail monthly sales report showing which regions met their quotas.\n",
    "\n",
    "2. **Diagnostic Analytics** (Why did it happen?): This involves \"drilling down\" into the data to find dependencies and causes.\n",
    "   - Example: Investigating why sales dropped in May and discovering it was due to a specific supply chain bottleneck.\n",
    "\n",
    "3. **Predictive Analytics** (What will happen?): This uses statistical models and machine learning to forecast future trends.\n",
    "   - Example: A bank estimating the likelihood of a customer defaulting on a loan based on their credit history.\n",
    "\n",
    "4. **Prescriptive Analytics** (How can we make it happen?): The most advanced stage, where the analysis recommends specific actions to achieve an optimal outcome.\n",
    "   - Example: An airline's pricing algorithm automatically adjusting ticket costs in real-time based on demand and weather patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Steps in Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading\n",
    "\n",
    "Gather relevant data from sources:\n",
    "\n",
    "1. Files (csv, excel, txt, json, xml, pdf, etc.)\n",
    "2. Surveys (Google Forms, SurveyMonkey)\n",
    "3. Web Scraping (BeautifulSoup, Scrapy, Selenium)\n",
    "4. APIs (Twitter, Facebook, Google Maps, etc.)\n",
    "5. Databases (SQL, NoSQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Cleaning\n",
    "\n",
    "Prepare data for analysis by:\n",
    "\n",
    " 1. Handle missing values\n",
    "     1. Remove rows with missing values\n",
    "     2. Impute missing values\n",
    "         - Mean, Median, Mode\n",
    "         - Forward fill, Backward fill\n",
    "         - Interpolation\n",
    "     3. Drop columns\n",
    " 2. Remove duplicates\n",
    " 3. Correct errors (invalid values)\n",
    " 4. Standardize feature names\n",
    " 5. Remove irrelevant and redundant features\n",
    " 6. Standardize data:\n",
    "     1. Convert data types (e.g., `str -> datetime`)\n",
    "     2. inconsistencies (e.g., `Female` and `F` both present in `gender` column)\n",
    "     3. One format for dates, phone numbers, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Transformation\n",
    "\n",
    "### 2.1 Scaling & Outlier Treatment\n",
    "\n",
    "1. Scale the data:\n",
    "    1. [**Normalize**](../techniques/02_transformation/normalize.ipynb)\n",
    "        - Log Transformation\n",
    "    2. [**Standardize**](../techniques/02_transformation/feature_scaling.ipynb)\n",
    "        - Z-score\n",
    "        - Min-max Scaling\n",
    "        - Robust Scaling\n",
    "2. [**Handle Outliers**](./L05_outliers.ipynb)\n",
    "    - Z-score method\n",
    "    - IQR method\n",
    "    - 95th percentile\n",
    "    - 99th percentile\n",
    "    - Domain knowledge\n",
    "3. Handle data imbalance\n",
    "4. Encode categorical variables (e.g., one-hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 [Feature Engineering](../techniques/02_transformation/feature_engineering.ipynb)\n",
    "\n",
    "Based on domain knowledge and questions to be answered:\n",
    "\n",
    "1. Create new variables\n",
    "    1. `age` from `date_of_birth`\n",
    "    2. `BMI` from `weight` and `height`\n",
    "    3. `season` from `date`\n",
    "2. *Data Enrichment* - Add new data from external sources\n",
    "    1. Geocoding (convert address to latitude and longitude using **Google Maps API**)\n",
    "    2. Sentiment analysis (analyze text data using **OpenAI API**)\n",
    "3. *Binning*\n",
    "    1. `age_group` from `age`\n",
    "    2. `income_group` from `income`\n",
    "    3. `weight_category` from `weight`\n",
    "4. Handle date-time variables\n",
    "    1. Extract year, month, day, day of week, etc.\n",
    "    2. Time since last purchase\n",
    "    3. Time since first visit\n",
    "5. Aggregate data\n",
    "    1. `total_sales` from `sales` table\n",
    "    2. `orders_count` from `orders` table\n",
    "    3. `maximum_amount` from `transactions` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 [Feature Selection](../techniques/02_transformation/feature_selection.ipynb)\n",
    "\n",
    "1. Select Features\n",
    "    1. Correlation Coefficient\n",
    "    2. Mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [Analysis, Modeling & Interpretation](L04_statistics.ipynb)\n",
    "\n",
    "- Descriptive Analytics: what happened?\n",
    "- Diagnostic Analytics: why did it happen?\n",
    "- Predictive Analytics: what will happen?\n",
    "- Prescriptive Analytics: how can we make it happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Uni-variate Analysis\n",
    "\n",
    "Understand the distribution of each variable.\n",
    "\n",
    "1. *Descriptive Statistics*\n",
    "    - Measure of central tendency (mean, median, mode)\n",
    "    - Dispersion (range, variance, standard deviation)\n",
    "    - Shape (skewness, kurtosis).\n",
    "2. *Visualizations*\n",
    "    - Histogram\n",
    "    - Boxplot\n",
    "    - Density plot\n",
    "    - Violin plot\n",
    "    - Bar plot\n",
    "    - Pie chart\n",
    "    - Frequency table\n",
    "    - Word cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Multi-variate Analysis\n",
    "\n",
    "Understand the relationship between multiple variables.\n",
    "\n",
    "1. *Descriptive Statistics*\n",
    "   - Covariance\n",
    "   - Correlation\n",
    "2. *Visualizations*\n",
    "   - Scatter plot\n",
    "   - Line plot\n",
    "   - Heatmap\n",
    "   - Pairplot\n",
    "   - Boxplot\n",
    "   - Violin plot\n",
    "   - Bar plot\n",
    "   - Stacked bar plot\n",
    "   - Grouped bar plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Modeling\n",
    "\n",
    "1. Make **inference** about population from sample\n",
    "2. **Quantify relationships** (regression)\n",
    "3. **Hypothesis testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Communication\n",
    "\n",
    "1. *Reports*: Jupyter Notebook\n",
    "2. *Dashboards*: Tableau, Power BI, Google Data Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Packages for Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python tools for data science are built on top of the following fundamental packages/libraries:\n",
    "\n",
    "- **NumPy**: The fundamental **package** for scientific computing with Python.\n",
    "- **SciPy**: Fundamental **algorithms** for scientific computing in Python.\n",
    "- **Matplotlib** is a comprehensive library for creating static, animated, and interactive **visualizations** in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such Python libraries use **C** underneath to achieve high performance, yet provides it in a simple Pythonic Interface / API. As shown in the image below (for NumPy):\n",
    "\n",
    "![Numpy Languages](../assets/numpy-languages.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following libraries in this course:\n",
    "\n",
    "1. **Pandas**: for data wrangling and analysis.\n",
    "2. **Seaborn**: for data visualization.\n",
    "3. **statsmodels**: for statistical modeling and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/intro/ds_stack.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
